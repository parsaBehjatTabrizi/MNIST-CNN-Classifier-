{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "At first we add necessary libraries wich is\n",
        "tensorflow\n",
        "tensirflow.keras\n",
        "tensorflow.heras.dataset\n",
        "google.colab as drive and files\n",
        "and at the end ad the OS library"
      ],
      "metadata": {
        "id": "tW71-jLpzfS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#adding the necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from google.colab import drive, files\n",
        "import os"
      ],
      "metadata": {
        "id": "a4AfzvqPzouA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "his code defines constants for image size, number of classes, batch size, epochs, and the model's save filename, ensuring readability and easy modification throughout the script."
      ],
      "metadata": {
        "id": "q6qbeEnl4EQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "IMG_HEIGHT, IMG_WIDTH = 28, 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "MODEL_FILENAME = \"mnist_cnn.h5\""
      ],
      "metadata": {
        "id": "FNmL69if0J5L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part i add this function to save the result in google drive"
      ],
      "metadata": {
        "id": "Oij3Aet91jxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Google Drive (optional)\n",
        "def setup_drive():\n",
        "    drive.mount('/content/drive')\n",
        "    save_path = \"/content/drive/MyDriveYOUR FOLDER NAME\"\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    return save_path"
      ],
      "metadata": {
        "id": "hIc80f1H1mpP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function loads the MNIST dataset, reshapes the images to include a channel dimension (28, 28, 1), normalizes pixel values to the range [0, 1], and converts the labels into one-hot encoded format for training and evaluation."
      ],
      "metadata": {
        "id": "ag6o9DRN4aeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "def preprocess_data():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 1).astype(\"float32\") / 255.0\n",
        "    x_test = x_test.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 1).astype(\"float32\") / 255.0\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
        "    return (x_train, y_train), (x_test, y_test)\n"
      ],
      "metadata": {
        "id": "aqYoQBO14JsQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function defines a sequential CNN model with two convolutional layers (using ReLU activation), max pooling layers, a flattening layer, and two dense layers, including a softmax output layer for classification. It compiles the model with the Adam optimizer, categorical cross-entropy loss, and accuracy as the evaluation metric."
      ],
      "metadata": {
        "id": "kQlBQ8ZT4vZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CNN model\n",
        "def build_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n",
        "    ])\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "WgtdH5Ri4uJq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "def train_model(model, x_train, y_train, x_test, y_test):\n",
        "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(x_test, y_test))\n",
        "    return model"
      ],
      "metadata": {
        "id": "ev8xEUjJ43ga"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part i save the code on google drive base on the path that i give"
      ],
      "metadata": {
        "id": "UCRHFeJY9dOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model locally and to Google Drive\n",
        "def save_model(model, drive_path=None):\n",
        "    local_path = f\"./{MODEL_FILENAME}\"\n",
        "    model.save(local_path)\n",
        "    print(f\"Model saved locally at {local_path}\")\n",
        "    files.download(local_path)\n",
        "    if drive_path:\n",
        "        drive_save_path = os.path.join(drive_path, MODEL_FILENAME)\n",
        "        model.save(drive_save_path)\n",
        "        print(f\"Model also saved to Google Drive at {drive_save_path}\")"
      ],
      "metadata": {
        "id": "62Rjit9F9gc8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is the main workflow for training and saving a CNN model using TensorFlow. It optionally sets up Google Drive for saving the model remotely, preprocesses the MNIST dataset, builds and trains the CNN model using the training data, evaluates it on the test data, and saves the trained model locally and optionally to Google Drive. The evaluation results (test accuracy and loss) are then printed. The script executes this logic when run directly.\n"
      ],
      "metadata": {
        "id": "XLwZcAwu-9D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main logic\n",
        "def main():\n",
        "    # Optional: Set up Google Drive\n",
        "    try:\n",
        "        drive_save_path = setup_drive()\n",
        "    except Exception as e:\n",
        "        print(\"Failed to set up Google Drive. Saving only locally.\")\n",
        "        drive_save_path = None\n",
        "\n",
        "    # Load and preprocess data\n",
        "    (x_train, y_train), (x_test, y_test) = preprocess_data()\n",
        "\n",
        "    # Build and train the model\n",
        "    model = build_model()\n",
        "    model = train_model(model, x_train, y_train, x_test, y_test)\n",
        "\n",
        "    # Save the trained model\n",
        "    save_model(model, drive_save_path)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(f\"Test Accuracy: {acc:.4f}, Test Loss: {loss:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "LYtM7ow5-_C7",
        "outputId": "00066c0c-72aa-48c3-9133-5b4ead59a99e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Failed to set up Google Drive. Saving only locally.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 111ms/step - accuracy: 0.8737 - loss: 0.4624 - val_accuracy: 0.9801 - val_loss: 0.0623\n",
            "Epoch 2/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 103ms/step - accuracy: 0.9814 - loss: 0.0604 - val_accuracy: 0.9877 - val_loss: 0.0392\n",
            "Epoch 3/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 100ms/step - accuracy: 0.9877 - loss: 0.0380 - val_accuracy: 0.9887 - val_loss: 0.0346\n",
            "Epoch 4/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 102ms/step - accuracy: 0.9911 - loss: 0.0286 - val_accuracy: 0.9888 - val_loss: 0.0317\n",
            "Epoch 5/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 105ms/step - accuracy: 0.9934 - loss: 0.0217 - val_accuracy: 0.9900 - val_loss: 0.0316\n",
            "Epoch 6/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 109ms/step - accuracy: 0.9939 - loss: 0.0187 - val_accuracy: 0.9906 - val_loss: 0.0289\n",
            "Epoch 7/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 100ms/step - accuracy: 0.9957 - loss: 0.0144 - val_accuracy: 0.9902 - val_loss: 0.0298\n",
            "Epoch 8/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 105ms/step - accuracy: 0.9966 - loss: 0.0111 - val_accuracy: 0.9905 - val_loss: 0.0318\n",
            "Epoch 9/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 100ms/step - accuracy: 0.9971 - loss: 0.0083 - val_accuracy: 0.9915 - val_loss: 0.0304\n",
            "Epoch 10/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 100ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.9902 - val_loss: 0.0351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved locally at ./mnist_cnn.h5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_67bf2db5-fcad-4df1-9ea9-ef913902c121\", \"mnist_cnn.h5\", 2741696)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9902, Test Loss: 0.0351\n"
          ]
        }
      ]
    }
  ]
}
